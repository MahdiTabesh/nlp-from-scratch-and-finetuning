{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6892a0-1950-4fa7-9976-58f580dda29a",
   "metadata": {},
   "source": [
    "# Spam Classification with BERT + LoRA\n",
    "Parameter-efficient fine-tuning of BERT for SMS spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c15f62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2305,
     "status": "ok",
     "timestamp": 1746139965824,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "85c15f62",
    "outputId": "0f188236-0cbe-4e4a-fd8f-a0060b150d30"
   },
   "outputs": [],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6GisTlddPg5T",
   "metadata": {
    "executionInfo": {
     "elapsed": 8260,
     "status": "ok",
     "timestamp": 1746139974087,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "6GisTlddPg5T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random\n",
    "from torchmetrics.classification import Recall, Accuracy, AUROC, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678adfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1746139974674,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "3678adfa",
    "outputId": "649e5c1d-4e71-4a52-9dda-e53f34a9bffa"
   },
   "outputs": [],
   "source": [
    "!wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "!unzip -o smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892553d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1746139974821,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "d892553d",
    "outputId": "5ba63d62-b38b-476c-86cc-3154efe86152"
   },
   "outputs": [],
   "source": [
    "!unzip -o smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d5e84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1746139974937,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "dd3d5e84",
    "outputId": "9a810711-ebf5-4424-c01f-82347d7d174a"
   },
   "outputs": [],
   "source": [
    "!head -10 SMSSpamCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b12150d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1746139975504,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "9b12150d",
    "outputId": "2b63f6be-5111-4e2a-dc09-4abb62ece4bb"
   },
   "outputs": [],
   "source": [
    "!wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'\n",
    "!unzip -o smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a736a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 2125,
     "status": "ok",
     "timestamp": 1746139977663,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "98a736a1",
    "outputId": "4c25077a-30ad-40eb-ff6b-816484dcd176"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5574,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5171,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\\n\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f04e7f88-6bf5-4df2-9852-a1ff3e7c3cbc\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f04e7f88-6bf5-4df2-9852-a1ff3e7c3cbc')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f04e7f88-6bf5-4df2-9852-a1ff3e7c3cbc button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f04e7f88-6bf5-4df2-9852-a1ff3e7c3cbc');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-944ac324-96f7-4af3-a9de-2ee04c8161bf\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-944ac324-96f7-4af3-a9de-2ee04c8161bf')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-944ac324-96f7-4af3-a9de-2ee04c8161bf button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                    Ok lar... Joking wif u oni...\\n\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'SMSSpamCollection'\n",
    "df = pd.DataFrame({'label':int(), 'text':str()}, index = [])\n",
    "with open(file_path) as f:\n",
    "    for line in f.readlines():\n",
    "        split = line.split('\\t')\n",
    "        df = pd.concat([\n",
    "                df,\n",
    "                pd.DataFrame.from_dict({\n",
    "                    'label': [1 if split[0] == 'spam' else 0],\n",
    "                    'text': [split[1]]\n",
    "                })\n",
    "            ],\n",
    "            ignore_index=True\n",
    "        )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a5cb02",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1746139977675,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "79a5cb02"
   },
   "outputs": [],
   "source": [
    "text = df.text.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce193a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1746139978085,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "dce193a4",
    "outputId": "b8a3a65b-59bd-4260-9006-ebb1374acc6d"
   },
   "outputs": [],
   "source": [
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c00a3e7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1746139978140,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "c00a3e7e",
    "outputId": "91381936-f7ca-422b-f9f2-a8b9e3bdbec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═════════════╕\n",
      "│ Tokens    │   Token IDs │\n",
      "╞═══════════╪═════════════╡\n",
      "│ do        │        2079 │\n",
      "├───────────┼─────────────┤\n",
      "│ you       │        2017 │\n",
      "├───────────┼─────────────┤\n",
      "│ realize   │        5382 │\n",
      "├───────────┼─────────────┤\n",
      "│ that      │        2008 │\n",
      "├───────────┼─────────────┤\n",
      "│ in        │        1999 │\n",
      "├───────────┼─────────────┤\n",
      "│ about     │        2055 │\n",
      "├───────────┼─────────────┤\n",
      "│ 40        │        2871 │\n",
      "├───────────┼─────────────┤\n",
      "│ years     │        2086 │\n",
      "├───────────┼─────────────┤\n",
      "│ ,         │        1010 │\n",
      "├───────────┼─────────────┤\n",
      "│ we        │        2057 │\n",
      "├───────────┼─────────────┤\n",
      "│ '         │        1005 │\n",
      "├───────────┼─────────────┤\n",
      "│ ll        │        2222 │\n",
      "├───────────┼─────────────┤\n",
      "│ have      │        2031 │\n",
      "├───────────┼─────────────┤\n",
      "│ thousands │        5190 │\n",
      "├───────────┼─────────────┤\n",
      "│ of        │        1997 │\n",
      "├───────────┼─────────────┤\n",
      "│ old       │        2214 │\n",
      "├───────────┼─────────────┤\n",
      "│ ladies    │        6456 │\n",
      "├───────────┼─────────────┤\n",
      "│ running   │        2770 │\n",
      "├───────────┼─────────────┤\n",
      "│ around    │        2105 │\n",
      "├───────────┼─────────────┤\n",
      "│ with      │        2007 │\n",
      "├───────────┼─────────────┤\n",
      "│ tattoos   │       18395 │\n",
      "├───────────┼─────────────┤\n",
      "│ ?         │        1029 │\n",
      "╘═══════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence():\n",
    "    '''Displays the tokens and respective IDs of a random text sample'''\n",
    "    index = random.randint(0, len(text)-1)\n",
    "    table = np.array([tokenizer.tokenize(text[index]),\n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
    "    print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d0895",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2621,
     "status": "ok",
     "timestamp": 1746139980764,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "e85d0895",
    "outputId": "c1d74905-a07b-4fa5-b6ad-95ecff18920b"
   },
   "outputs": [],
   "source": [
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "    '''\n",
    "    Tokenize a text string and return input IDs + attention mask (padded to max length 128).\n",
    "    '''\n",
    "\n",
    "  return tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "\n",
    "for sample in text:\n",
    "    encoding_dict = preprocessing(sample, tokenizer)\n",
    "    token_id.append(encoding_dict['input_ids'])\n",
    "    attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.tensor(token_id)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "222e06a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1746139980801,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "222e06a7",
    "outputId": "3cb52761-6655-49fa-d29e-7fa0c425512e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤═════════════╤══════════════════╕\n",
      "│ Tokens   │   Token IDs │   Attention Mask │\n",
      "╞══════════╪═════════════╪══════════════════╡\n",
      "│ [CLS]    │         101 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ not      │        2025 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ yet      │        2664 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ chi      │        9610 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ ##kk     │       19658 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ ##u      │        2226 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ .        │        1012 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ .        │        1012 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ wat      │       28194 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ ab       │       11113 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ ##t      │        2102 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ u        │        1057 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ ?        │        1029 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [SEP]    │         102 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "╘══════════╧═════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence_encoding():\n",
    "    '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
    "    index = random.randint(0, len(text) - 1)\n",
    "    tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
    "    token_ids = [i.numpy() for i in token_id[index]]\n",
    "    attention = [i.numpy() for i in attention_masks[index]]\n",
    "    table = np.array([tokens, token_ids, attention]).T\n",
    "    print(\n",
    "        tabulate(\n",
    "            table,\n",
    "            headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
    "            tablefmt = 'fancy_grid')\n",
    "    )\n",
    "\n",
    "print_rand_sentence_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c2c10b",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746139980808,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "e1c2c10b"
   },
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "# Batch size for training\n",
    "batch_size = 16\n",
    "\n",
    "# Stratified split into train/validation indices\n",
    "train_idx, val_idx = train_test_split(np.arange(len(labels)), test_size=val_ratio, stratify=labels, random_state=42)\n",
    "\n",
    "# Build TensorDatasets for train/validation\n",
    "train_set = TensorDataset(token_id[train_idx], attention_masks[train_idx], labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], attention_masks[val_idx], labels[val_idx])\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(train_set, sampler=RandomSampler(train_set), batch_size=batch_size)\n",
    "\n",
    "validation_dataloader = DataLoader(val_set, sampler=SequentialSampler(val_set), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zqd2vdeT1Ywe",
   "metadata": {
    "id": "zqd2vdeT1Ywe"
   },
   "source": [
    "Define the LoRA specific layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de762ca",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1746139980814,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "0de762ca"
   },
   "outputs": [],
   "source": [
    "# Define a LoRA Layer which has A, B and alpha parameters\n",
    "class LoRALayer(torch.nn.Module):\n",
    "  def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "    super().__init__()\n",
    "\n",
    "    self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "\n",
    "    torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "\n",
    "    self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "    self.alpha = alpha\n",
    "    self.rank = rank\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.matmul(self.A).matmul(self.B)\n",
    "    return x * (self.alpha / self.rank)\n",
    "\n",
    "# Linear layer wrapped with a LoRA adapter (residual add)\n",
    "class LoRALinear(torch.nn.Module):\n",
    "  def __init__(self, linear, rank, alpha):\n",
    "    super().__init__()\n",
    "    self.linear = linear\n",
    "    self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Base linear + LoRA adaptation\n",
    "    return self.linear(x) + self.lora(x)\n",
    "\n",
    "def lora_linear_replace(model, rank, alpha):\n",
    "  # Recursively replace nn.Linear with LoRALinear\n",
    "  for name, module in model.named_children():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "      setattr(model, name, LoRALinear(module, rank, alpha))\n",
    "    else:\n",
    "      # Continue traversal into submodules\n",
    "      lora_linear_replace(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bcf8c4",
   "metadata": {
    "id": "40bcf8c4"
   },
   "source": [
    "### Load specific versions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f85fc88e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1746139980948,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "f85fc88e",
    "outputId": "6100e6cd-f7a2-4afc-d2d4-f6c53ef48a56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345552\n"
     ]
    }
   ],
   "source": [
    "# Load BERT for binary classification (suppress extra outputs)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased', num_labels=2, output_attentions=False, output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Turn off all gradients of the model to start\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Toggle LoRA or full/partial fine-tuning\n",
    "use_lora  = True\n",
    "# If this is False, turn off gradients\n",
    "fine_tune = False\n",
    "# Track the number of trainable parameters\n",
    "total_parameters = 0\n",
    "\n",
    "if use_lora:\n",
    "  # Replace Linear layers with LoRA-augmented versions\n",
    "  lora_linear_replace(model, rank=8, alpha=8)\n",
    "  # Count LoRA trainable parameters\n",
    "  for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            total_parameters += param.numel()\n",
    "else:\n",
    "  # If fine_tune is off, turn off gradients for all layers other than classifier\n",
    "  if not fine_tune:\n",
    "    # Train only the classifier layer\n",
    "    for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "            total_parameters += param.numel()\n",
    "  else:\n",
    "    # Fine-tune the entire model\n",
    "    for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "            total_parameters += param.numel()\n",
    "\n",
    "print(total_parameters)\n",
    "\n",
    "if use_lora:\n",
    "  assert(total_parameters == 1345552)\n",
    "else:\n",
    "  if fine_tune:\n",
    "    assert(total_parameters == 109483778)\n",
    "  else:\n",
    "    assert(total_parameters == 1538)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7368b2e",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746139980959,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "c7368b2e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a36b60bf",
   "metadata": {
    "id": "a36b60bf"
   },
   "source": [
    "### Set the model to the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "071b1a84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1746139981048,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "071b1a84",
    "outputId": "2e998e3d-00e1-45de-f324-6d6173fdaf8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "# Select available device\n",
    "if platform.system() == 'Darwin':\n",
    "    device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "elif platform.system() == 'Linux':\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4811b9f5",
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1746139981369,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "4811b9f5"
   },
   "outputs": [],
   "source": [
    "_ = model.to(device)\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nJ9A9Q6Zo9z8",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1746139981388,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "nJ9A9Q6Zo9z8"
   },
   "outputs": [],
   "source": [
    "# AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad],\n",
    "    lr = 5e-5,\n",
    "    eps = 1e-08\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fc3a1",
   "metadata": {
    "id": "765fc3a1"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf0b712e",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1746139981396,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "bf0b712e"
   },
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "accuracy = Accuracy(task=\"binary\")\n",
    "recall = Recall(task=\"binary\")\n",
    "precision = Precision(task=\"binary\")\n",
    "auroc = AUROC(task=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "Zw_zk3ZPpZXK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1746139981408,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "Zw_zk3ZPpZXK",
    "outputId": "0ee49843-c653-498c-aae8-e60714cdbacc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "084519f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41020,
     "status": "ok",
     "timestamp": 1746140022430,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "084519f5",
    "outputId": "dbfbe5fb-ca12-41d5-b85f-1d604824815a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "Epoch:  50%|█████     | 1/2 [00:20<00:20, 20.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.1959\n",
      "\t - Validation Accuracy: 0.9875\n",
      "\t - Validation Precision: 0.8560\n",
      "\t - Validation Recall: 0.8643\n",
      "\t - Validation AUROC: 0.9050\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100%|██████████| 2/2 [00:41<00:00, 20.55s/it]\n",
      "100%|██████████| 2/2 [00:41<00:00, 20.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.0260\n",
      "\t - Validation Accuracy: 0.9920\n",
      "\t - Validation Precision: 0.8702\n",
      "\t - Validation Recall: 0.8643\n",
      "\t - Validation AUROC: 0.9063\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and validation loop\n",
    "import tqdm\n",
    "for _ in tqdm.tqdm(trange(epochs, desc = 'Epoch')):\n",
    "\n",
    "    # ----- Training -----\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_labels.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    # ----- Validation -----\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_auroc = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          # Forward pass\n",
    "            eval_output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        labels = b_labels.cpu()\n",
    "        predicted_labels = torch.argmax(eval_output.logits, dim=1).cpu()\n",
    "\n",
    "        val_accuracy.append(accuracy(predicted_labels, labels).item())\n",
    "        val_recall.append(recall(predicted_labels, labels).item())\n",
    "        val_precision.append(precision(predicted_labels, labels).item())\n",
    "        val_auroc.append(auroc(torch.softmax(eval_output.logits, dim=1)[:, 1].cpu(), labels).item())\n",
    "\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)))\n",
    "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)))\n",
    "    print('\\t - Validation AUROC: {:.4f}\\n'.format(sum(val_auroc)/len(val_auroc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c029bd94",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1746140022435,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "c029bd94"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13d64bc6",
   "metadata": {
    "id": "13d64bc6"
   },
   "source": [
    "### Test on a specific sentence, see the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dfcd9e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1746140122525,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "6dfcd9e7",
    "outputId": "0c4bd4fd-5582-4886-ec1d-629be7b3b8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence:  WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "Predicted Class:  Spam\n"
     ]
    }
   ],
   "source": [
    "new_sentence = 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'\n",
    "\n",
    "# Tokenize and convert to tensors\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Convert input_ids and attention_mask to tensors\n",
    "encoding['input_ids'] = torch.tensor(encoding['input_ids']).unsqueeze(0)\n",
    "encoding['attention_mask'] = torch.tensor(encoding['attention_mask']).unsqueeze(0)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim = 0)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "# Forward pass, calculate logit predictions\n",
    "with torch.no_grad():\n",
    "    output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "\n",
    "prediction = 'Spam' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'Ham'\n",
    "\n",
    "print('Input Sentence: ', new_sentence)\n",
    "print('Predicted Class: ', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9055d",
   "metadata": {
    "id": "dae9055d"
   },
   "source": [
    "## Experiment: Full Fine-Tuning vs Frozen BERT vs LoRA\n",
    "\n",
    "We trained three configurations on the SMS Spam dataset to compare adaptation strategies:\n",
    "\n",
    "1) **Frozen BERT (feature extractor; train classifier only)**\n",
    "- Val Acc: **0.8657**\n",
    "- Precision: **0.0000**\n",
    "- Recall: **0.0000**\n",
    "- AUROC: **0.8466**\n",
    "- Misclassified the spam example as **Ham**.\n",
    "- Takeaway: features stay generic; poor recall for spam.\n",
    "\n",
    "2) **Full Fine-Tuning (BERT + classifier)**\n",
    "- Val Acc: **0.9893**\n",
    "- Precision: **0.8476**\n",
    "- Recall: **0.8210**\n",
    "- AUROC: **0.9089**\n",
    "- Correctly classified the spam example.\n",
    "- Takeaway: task-specific adaptation boosts all metrics.\n",
    "\n",
    "3) **LoRA Fine-Tuning (parameter-efficient)**\n",
    "- Val Acc: **0.9920**\n",
    "- Precision: **0.8702**\n",
    "- Recall: **0.8543**\n",
    "- AUROC: **0.9063**\n",
    "- Correctly classified the spam example.\n",
    "- Takeaway: near full-FT quality while updating far fewer params.\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Config            | Accuracy | Precision | Recall | AUROC  |\n",
    "|-------------------|---------:|----------:|-------:|:------:|\n",
    "| Frozen BERT       |  0.8657  |   0.0000  | 0.0000 | 0.8466 |\n",
    "| Full Fine-Tuning  |  0.9893  |   0.8476  | 0.8210 | 0.9089 |\n",
    "| LoRA              |  0.9920  |   0.8702  | 0.8543 | 0.9063 |\n",
    "\n",
    "**Conclusion.** Freezing BERT underperforms due to lack of task adaptation. Full fine-tuning yields strong improvements. LoRA matches (or slightly exceeds) full fine-tuning on this task with a fraction of trainable parameters, making it a practical default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72020863",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1746140022465,
     "user": {
      "displayName": "Mahdi Saleh Tabesh",
      "userId": "07240825415212703464"
     },
     "user_tz": 240
    },
    "id": "72020863"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
